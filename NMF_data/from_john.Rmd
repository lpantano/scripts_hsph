---
output:
  knitrBootstrap::bootstrap_document:
    theme: readable
    highlight: zenburn
    theme.chooser: TRUE
    highlight.chooser: TRUE
  html_document:
    toc: true
    highlight: zenburn
---

last update `r date()`

```{r setupstate, echo=FALSE}
library(knitr)
opts_chunk$set(tidy=TRUE, cache=TRUE,  highlight=TRUE, figalign="center", echo=TRUE, warning=FALSE, error=FALSE, message=FALSE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=120))
options(width=200,bitmapType = 'cairo')
# render_2_drop("from_john.Rmd","proteomics")
```

# SETUP

```{r myR, echo=FALSE}
library(myRfunctions)
```


## Directories and Variables
- either local or using Odyssey

```{r setup}
# baseDir <- "/n/hsphS10/hsphfs1/chb/projects/aw_NMF_proteomics/June2015"
baseDir <- "~/ody/chb/projects/aw_NMF_proteomics/June2015"

dataDir <- file.path(baseDir, "data")
resultsDir <- file.path(baseDir, "results")
metaDir <- file.path(baseDir, "meta")
```

## Libraries

```{r libraries}
library(reshape2)
library(ggplot2)
library(readr)
library(dplyr)
library(pheatmap)
library(ggdendro)
library(CHBUtils)
library(edgeR)
library(plyr)
library(RUVSeq)
library(limma)
```

## Load Data

There are three separate datasets, each with the same data classes in each.

```{r loaddata}
rawdata.set0 <- read.csv(file.path(dataDir, "Set0", "Set0-Summary-2.csv"))
rawdata.set1 <- read.csv(file.path(dataDir, "Set1", "Set1-Summary-2.csv"))
rawdata.set2 <- read.csv(file.path(dataDir, "Set2", "Set2-Summary-2.csv"))
```

# Data Summarize

## Summarize/Collapse all identical phospho-residues
- same phospho-proteomic site can be represented in the data by a different peptide
- assuming they are all coming from the same origin, makes sense to just sum the values for identical phosphoresidues found on same proteins

```{r summarizephospresidues}
sumdata.set0 <- aggregate(cbind(Summed.126, Summed.127, Summed.128, Summed.129, Summed.130, Summed.131) ~ GeneName+Protein.Relative.Modifications.1, data=rawdata.set0, sum)
sumdata.set1 <- aggregate(cbind(Summed.126, Summed.127, Summed.128, Summed.129, Summed.130, Summed.131) ~ GeneName+Protein.Relative.Modifications.1, data=rawdata.set1, sum)
sumdata.set2 <- aggregate(cbind(Summed.126, Summed.127, Summed.128, Summed.129, Summed.130, Summed.131) ~ GeneName+Protein.Relative.Modifications.1, data=rawdata.set2, sum)
```

## Data Clean
- some lines have no signal, dropped them

```{r dataclean}
# remove any rows with zero counts for all samples
sumdata.set0 <- sumdata.set0[!(apply(sumdata.set0[, grep("Summed", names(sumdata.set0))], 1, function(x) all(x==0))),]
sumdata.set1 <- sumdata.set1[!(apply(sumdata.set0[, grep("Summed", names(sumdata.set1))], 1, function(x) all(x==0))),]
sumdata.set2 <- sumdata.set2[!(apply(sumdata.set0[, grep("Summed", names(sumdata.set2))], 1, function(x) all(x==0))),]
```

## Data exploration
- exploring best way to combine the different sets of data
- not all sets detected the same phosphoproteomic sites
- does it make a difference is we merge the datasets using only common phosphoproteomic sites or should we use all of them?

```{r dataexplore}
# merge datasets together - all phospho sites
sumdata.set.0.1. <- merge(sumdata.set0, sumdata.set1, by=c("GeneName", "Protein.Relative.Modifications.1"), suffixes=c(".0", ".1"), all=TRUE)
sumdata.set.0.1.2 <- merge(sumdata.set.0.1., sumdata.set2, by=c("GeneName", "Protein.Relative.Modifications.1"), all=TRUE)
sumdata <- sumdata.set.0.1.2
names(sumdata)[(ncol(sumdata)-5):ncol(sumdata)] <- paste(names(sumdata)[(ncol(sumdata)-5):ncol(sumdata)], ".2", sep="")
sumdata.m <- melt(sumdata, id.vars=c("GeneName", "Protein.Relative.Modifications.1"))
ggplot(sumdata.m, aes(x=value, col=variable) )+geom_density()+scale_x_log10()+ggtitle("Summed counts, all phospho sites")


# merge datasets together - only common phospho sites
sumdata.set.0.1. <- merge(sumdata.set0, sumdata.set1, by=c("GeneName", "Protein.Relative.Modifications.1"), suffixes=c(".0", ".1"))
sumdata.set.0.1.2 <- merge(sumdata.set.0.1., sumdata.set2, by=c("GeneName", "Protein.Relative.Modifications.1"))
sumdata <- sumdata.set.0.1.2
names(sumdata)[(ncol(sumdata)-5):ncol(sumdata)] <- paste(names(sumdata)[(ncol(sumdata)-5):ncol(sumdata)], ".2", sep="")
sumdata.m <- melt(sumdata, id.vars=c("GeneName", "Protein.Relative.Modifications.1"))
ggplot(sumdata.m, aes(x=value, col=variable) )+geom_density()+scale_x_log10()+ggtitle("Summed counts, common phospho sites")
```

- really can't see any reason to keep all the sites for this, might be important if we decide to use the edgeR method of normalization?
- going forward with just the common sites before normalization

## Normalize total counts for each sample
- first try simple method based on adjusting for total output for each sample
- scale values of samples so all samples have same total intensity scores for common phospho sites

```{r normvalues}
# using just total count norm
## merge datasets together - only common phospho sites
sumdata.set.0.1. <- merge(sumdata.set0, sumdata.set1, by=c("GeneName", "Protein.Relative.Modifications.1"), suffixes=c(".0", ".1"))
sumdata.set.0.1.2 <- merge(sumdata.set.0.1., sumdata.set2, by=c("GeneName", "Protein.Relative.Modifications.1"))
sumdata <- sumdata.set.0.1.2
names(sumdata)[(ncol(sumdata)-5):ncol(sumdata)] <- paste(names(sumdata)[(ncol(sumdata)-5):ncol(sumdata)], ".2", sep="")
## calc total intensities for each sample
colsums <- colSums(sumdata[, grep("Summed", names(sumdata))])
## calc multiplier modifier for each samples, based on sample with total lowest intensity
mods<- 1/(colsums/min(colsums))
## normalize summed data with multiplier modifier
normed.sums <- as.data.frame(t(t(sumdata[,grep("Summed", names(sumdata))])*mods))
## add normalized data to non-normed data
names(normed.sums) <- sub("Summed", "Normed", names(normed.sums))
data <- cbind(sumdata, normed.sums)
normed.data <- cbind(data[,1:2], data[,grep("Normed", names(data))])
normed.data$gene_phosphosite <- paste(normed.data$GeneName, normed.data$Protein.Relative.Modifications.1, sep="_")
row.names(normed.data) <- normed.data$gene_phosphosite
normed.data <- log2(normed.data[,grep("Normed", names(normed.data))] + 0.5)

# plot normed results
normed.data.m <- melt(normed.data)

ggplot(normed.data.m, aes(x=value, col=variable) )+geom_density()
heatmap(as.matrix(normed.data), labRow = NA)
myDist <- dist(t(1-cor(normed.data)))
myTree <- hclust(myDist, method = "ward.D2")
dhc <- as.dendrogram(myTree)
ggdendrogram(dhc)
```


## Using edgeR
- using  a library deigned for count data from RNA-seq, trying to see if it is effective for phosph-proteomic results
- adjusts for both total "library" size and RNA composition effects i.e. will compensate for outlier RNAs that might use up a significant proportion of the results, to avoid undersampling of of other genes in the sample
- here I used all the phosphoproteomic sites, as edgeR adjusts for "RNA" composition, and excluding "RNAs" might skew that in unexpected ways

>The calcNormFactors function normalizes for RNA composition by finding a set of scaling factors for the library sizes that minimize the log-fold changes between the samples for most genes.

```{r edgeRnorm}
# merge datasets together - all phospho sites
sumdata.set.0.1. <- merge(sumdata.set0, sumdata.set1, by=c("GeneName", "Protein.Relative.Modifications.1"), suffixes=c(".0", ".1"), all=TRUE)
sumdata.set.0.1.2 <- merge(sumdata.set.0.1., sumdata.set2, by=c("GeneName", "Protein.Relative.Modifications.1"), all=TRUE)
sumdata <- sumdata.set.0.1.2
names(sumdata)[(ncol(sumdata)-5):ncol(sumdata)] <- paste(names(sumdata)[(ncol(sumdata)-5):ncol(sumdata)], ".2", sep="")

# prep for edgeR import
phosphosites <- paste(sumdata[,1], sumdata[,2], sep="_")
sumdata <- cbind(phosphosites, sumdata[, grep("umm", names(sumdata))])
row.names(sumdata) <- sumdata$phosphosites
sumdata$phosphosites <- NULL
sumdata[is.na(sumdata)] <- 0

# import into edgeR object and calc norm factors
sumdata.dge <- DGEList(counts=sumdata)
sumdata.dge <- calcNormFactors(sumdata.dge)

# output normed data adjusted for library size and
normed.data.edger <- cpm(sumdata.dge, normalized.lib.sizes = TRUE, log = TRUE)

# subset to commmon phospho sites
normed.data.edger <- normed.data.edger[row.names(normed.data.edger) %in% row.names(normed.data),]
normed.data.edger <- as.data.frame(normed.data.edger)

# plot normed results
normed.data.edger.m <- melt(normed.data.edger)

ggplot(normed.data.edger.m, aes(x=value, col=variable) )+geom_density()
heatmap(as.matrix(normed.data.edger), labRow = NA)
myDist <- dist(t(1-cor(normed.data.edger)))
myTree <- hclust(myDist, method = "ward.D2")
dhc <- as.dendrogram(myTree)
ggdendrogram(dhc)
```

Both normlaization methods are insufficient to overcome the batch run effect ie. they are still clustering by batch. While we could account for batch in the differential "expression" equation we can't do this for NMF, we instead require a pre-adjusted matrix.

## Batch correction

Using either SVAseq or RUVseq

Batch here corresponds to "Set".
For sample classes, you can either load in the metadata, or just work off the sample numbers.

The metadata is a bit confusing,with different terms used for the same sample types.

resting bone marrow == RBM == unmobilized ==  D1
peripheral mobilized == PM == mobilized_spleen ==  D4

You'll notice that the same sample types are loaded in the same slots for all 3 assays.

i.e. Summed126 is consistently the same sample type

So,

resting bone marrow == RBM == unmobilized ==  D1 == 126,127 & 128
peripheral mobilized == PM == mobilized_spleen ==  D4 == 129,130 & 131



```{r svaseq}
metadata <- laply(strsplit(names(normed.data), "\\."), function(x) {
sample <- x[2]
batch <- x[3]
return(list(sample=sample, batch=batch))
})
metadata <- as.data.frame(metadata)
metadata$sampleclass <- ifelse(metadata$sample==126| metadata$sample==127 | metadata$sample==128, "D1", "D4")


set = newSeqExpressionSet(as.matrix(normed.data.edger))
difference <- matrix(data=c(c(1:3,7:9,13:15), c(4:6,10:12,16:18)), byrow=TRUE, nrow=2)
batch_ruv_emp <- RUVs(as.matrix(normed.data.edger), rownames(normed.data.edger), k=2, difference, isLog = T)

normed.suv <- as.data.frame((batch_ruv_emp$normalizedCounts))

normed.suv.m <- melt(normed.suv)

ggplot(normed.suv.m, aes(x=value, col=variable) )+geom_density()
heatmap(as.matrix(normed.suv), labRow = NA)
myDist <- dist(t(1-cor(normed.suv)))
myTree <- hclust(myDist, method = "ward.D2")
dhc <- as.dendrogram(myTree)
ggdendrogram(dhc)
```

```{r limma, results='asis'}
row.names(metadata) = names(sumdata.dge$counts)
dd = cbind(metadata, batch_ruv_emp$W)[,1:5]
dd$batch = as.factor(unlist(dd$batch))  

ma = model.matrix(~ 0 + sampleclass + batch, data=dd)
  
dat.voom = voom(batch_ruv_emp$normalizedCounts^2,design = ma, plot = TRUE)
dat.fit <- lmFit(dat.voom, ma)

cont.ma = makeContrasts(condition=sampleclassD4-sampleclassD1, levels=ma)
dat.fit.cont <- contrasts.fit(dat.fit, cont.ma)
dat.bayes <- eBayes(dat.fit.cont)

kable(summary(decideTests(dat.bayes)))

all_de = topTable(dat.bayes, coef="condition", number = Inf)
```


# Output to files

```{r output}
write.csv(normed.suv, file=file.path("normalized.data.suvseq.csv"))
write.csv(all_de, file=file.path("limma.voom.csv"))
# write.csv(normed.data.edger, file=file.path(dataDir, "Set2", "normalized.data.edgeR.csv"))
```

[normalized matrix](`r get_report_links("normalized.data.suvseq.csv")`)

[differential expression](`r get_report_links("limma.voom.csv")`)
