---
output:
    knitrBootstrap::bootstrap_document:
        theme: readable
        highlight: zenburn
        theme.chooser: TRUE
        highlight.chooser: TRUE
    html_document:
        toc: true
        highlight: zenburn

---
    
# Report

This report is removing duplicates using position of read 1 and primer of read 2.
Only uniquely mapped reads are annotated with ensembl gene GTF.

## Overview

There are 4 samples, `s1` and `s2` get long fragments and `s3` and `s4` get short fragments.
Among the pairs, there are some difference in protocol, like amplification cycles 
and different ligation method (i am guessing from the metadata)

[s1](`r get_report_html("~/repos/pipelines/daley_tailseq/reports/2.0/s1_Aligned.out_fastqc.html")`)
[s2](`r get_report_html("~/repos/pipelines/daley_tailseq/reports/2.0/s2_Aligned.out_fastqc.html")`)
[s3](`r get_report_html("~/repos/pipelines/daley_tailseq/reports/2.0/s3_Aligned.out_fastqc.html")`)
[s4](`r get_report_html("~/repos/pipelines/daley_tailseq/reports/2.0/s4_Aligned.out_fastqc.html")`)




## Method

* Map read 1
* QC for read 1
* Detect polyA in read 2: remove first 5 nt TAG at position ~17
* Overlap read 1 with genes and retrieve read-gene information
* Summarize read 1 and read 2 to get information for each gene (counts, polyA, modifications)
As well an extra tuner step is applied to get more precisely polyA fragment.
* Remove false positive polyA. I mapped read 2
to the genome and remove reads that map entirely since we are trying to detect 
post-modifications. Make sense? There were a lot of reads with short polyA
that ended up with long modifications, and mapped perfectly to the genome. 

### Setup: loading packages and data
    
```{r setup,cache=FALSE}
library(knitr)
library(rmarkdown)
library(knitrBootstrap)
library(ggplot2)
library(gplots)
library(reshape)
library(DESeq2)
library(edgeR)
library(genefilter)
library(CHBUtils)
library(gtools)
library(gridExtra)
library(devtools)
library(dplyr)
library(rjson)
library(GGally)
source("~/repos/myRfunctions/transactions.R")
dn <- "daley_tailseq/2.0_rmdup_read2_unique"
root_path<-"~/ody/projects/daley_mRNA_mod/tailseq-2.0"
path_files = "~/repos/pipelines/daley_tailseq/reports/2.0_rmdup_read2/"
```

```{r render,eval=FALSE,cache=FALSE}
knitr::opts_chunk$set(tidy=TRUE, highlight=TRUE, dev="png",
                      cache=TRUE, highlight=TRUE, autodep=TRUE, warning=FALSE, error=FALSE,
                      cache.path="~/.cache/tailseq-report/html_cached_2.0_v2/", eval=TRUE,
                      message=FALSE, prompt=TRUE, comment='', fig.cap='', bootstrap.show.code=FALSE)
render_2_drop("~/repos/pipelines/daley_tailseq/reports/2.0_rmdup_read2/tailseq_2.0_rmdup_read2.rmd",dn)
```


```{r load,cache=FALSE}
setwd(root_path)
```

```{r functions,cache=F}
source("~/repos/pipelines/daley_tailseq/reports/functions.R")
```

```{r venn-function,cache=FALSE}
get_entrez = function(g){
  require(biomaRt)
  ensembl = useMart('ensembl', dataset = "hsapiens_gene_ensembl")
  df = getBM(attributes=c("ensembl_gene_id", "entrezgene"), filters="ensembl_gene_id", values=g,mart=ensembl)
  return(df[,2])
}


do_df = function(sample, groups){
    data.frame(gene=groups[[sample]],sample=sample,is=1)
}

do_venn_d = function(groups)
{
    n = length(groups)
    all_genes = do.call(rbind, lapply(names(groups), do_df, groups) )
    
    total_genes = all_genes %>% group_by(sample) %>% summarise(total = sum(is)) %>% ungroup()
    all_genes = reshape(all_genes, timevar = "sample",idvar = "gene", direction = "wide")
    all_genes[is.na(all_genes)] = 0
    
    all_genes_sum = all_genes %>% group_by_(.dots = (names(all_genes[,1:n+1]))) %>% summarise(total = n()) %>% ungroup()
    per = apply( all_genes_sum, 1, function(x){
        unlist((x[n+1]/as.vector(total_genes[,2])) * x[1:n] * 100 )
        })
    per[per==0] = NA
    rownames(per) = names(groups)
 
    num = apply( all_genes_sum, 1, function(x){
        unlist(x[n+1] * x[1:n]  )
        })
    num[num==0] = NA
    rownames(num) = names(groups)
 
    
    aheatmap( t(as.matrix(t(per))), annCol = all_genes_sum[,1:n], Colv = NA, Rowv = NA,cellheight = 45, cellwidth = 25, fontsize=9, txt = num )
    
}

```


## polyA in read-2

purple (reads with polyA), blue (reads without polyA) and orange (reads with polyA < 6 nt) are the total amount of reads. red (modifications) are reads with modifications after polyA. And green are the ones without the 5 nt TAG along the read.

These are the stats of read_2 before taking into account the ones where the paired
read_1 maps onto a gene. 

And we applied here another filter to reduce the number of false positive of polyA.
Normally short polyA with long modifications are removed here. We just don't count when read2 maps perfectly to the genome and is at the expected distance from the read1.

```{r ploya,cache=FALSE}
dd = data.frame()
for (file in list.files(paste0(root_path,"/work_rmdup_read2/"), "stat$") ){
    data = read.table(paste0(root_path, "/work_rmdup_read2/", file) )
    dd = rbind(dd, data)
}
dd$sample = c(rep("s1",5), rep("s2",5), rep("s3",5) , rep("s4",5) )
ggplot( dd, aes( x=sample, y=V2, fill=V1 ) ) +
    geom_bar( stat = 'identity', position = 'dodge') + 
    scale_fill_brewer( palette = "Set1" ) +
    labs( list( y="reads" ) )

```

## After filtering

After that filter, we reduce the total number of reads, but still have a lot.
Similar number than public database.
Showing sample 1 only. 

```{r after-filtering,cache=FALSE}
s1_raw = read.table(paste0(root_path,"/work_rmdup_read2/s1_summary.dat"))
poly_read_summary(s1_raw)
```

### polyA > 200 and size >= 6 nt

```{r polya-filter-200,cache=FALSE}
s1 = filter_out(s1_raw,200)
s2_raw = read.table(paste0(root_path,"/work_rmdup_read2/s2_summary.dat"))
s2 = filter_out(s2_raw,200)
s3_raw = read.table(paste0(root_path,"/work_rmdup_read2/s3_summary.dat"))
s3 = filter_out(s3_raw,200)
s4_raw = read.table(paste0(root_path,"/work_rmdup_read2/s4_summary.dat"))
s4 = filter_out(s4_raw,200)
genes_s1 = get_set_genes(s1)
genes_s2 = get_set_genes(s2)
genes_s3 = get_set_genes(s3)
genes_s4 = get_set_genes(s4)


```


```{r public-data,cache=FALSE}
sp<-read.table("~/ody/projects/daley_mRNA_mod/tailseq_GSE51299/SPtable.csv",header=T,sep=",")
library(biomaRt)
mart = useMart("ensembl", dataset="hsapiens_gene_ensembl")
g <- getBM( attributes=c("ensembl_gene_id", "hgnc_symbol","gene_biotype") , filters=
"hgnc_symbol"    , values =as.character(sp$Gene.Name) ,mart=mart)
idx<-match(sp$Gene.Name,g$hgnc_symbol)
sp$ens<-g[idx,1]
sp.f<-sp[,c(24,2,3,11,12,13,14,15,16,17,18,19,22),]

public = vector("list")

sp.f = sp.f[!is.na(sp.f$ens),]
public[["polyA"]] = data.frame(V1=sp.f$ens, V2="polyA", V3=sp.f$Total.poly.A...tags)

p = sp.f[sp.f[,5]>1,1]
public[["a"]] = data.frame(V1=p, V2="U", V3=sp.f[sp.f$ens %in% p ,5])

p = sp.f[sp.f[,8]>1,1]
public[["aa"]] = data.frame(V1=p, V2="UU", V3=sp.f[sp.f$ens %in% p ,8])

p = sp.f[sp.f[,11]>1,1]
public[["a3"]] = data.frame(V1=p, V2="U3", V3=sp.f[sp.f$ens %in% p ,11])

public_raw = do.call(rbind, public)

#sp_reworked<-read.table("~/ody/projects/daley_mRNA_mod/tailseq_GSE51299/summary.complete.8As",header=F,sep="\t")
#rw_raw = sp_reworked[,c(1,3,4)]
#names(rw_raw) = c("V1","V2","V3")
#rw_raw$V2 = as.character(rw_raw$V2)
#rw_raw$V2[rw_raw$V2=="None"] = "polyA"

public = filter_out_public(public_raw,200)
genes_public = get_set_genes_public(public)
#rw = filter_out(rw_raw,200)
#genes_rw = get_set_genes(rw)

```


```{r biotype, eval=FALSE}
s1_g <- getBM( attributes=c("ensembl_gene_id", "hgnc_symbol","gene_biotype") , filters=
"ensembl_gene_id"    , values =as.character(s1[[1]]) ,mart=mart)
s2_g <- getBM( attributes=c("ensembl_gene_id", "hgnc_symbol","gene_biotype") , filters=
"ensembl_gene_id"    , values =as.character(s2[[1]]) ,mart=mart)
s3_g <- getBM( attributes=c("ensembl_gene_id", "hgnc_symbol","gene_biotype") , filters=
"ensembl_gene_id"    , values =as.character(s3[[1]]) ,mart=mart)
s4_g <- getBM( attributes=c("ensembl_gene_id", "hgnc_symbol","gene_biotype") , filters=
"ensembl_gene_id"    , values =as.character(s4[[1]]) ,mart=mart)
```


#### Common genes among 4 samples

I changed venn diagrams by heatmaps. Each top bar is a sample, when two bars
overlaps, the cells below are the number of genes in common. The color mean the
percentage of common genes for that sample. 

For instance, the first right column shows the common genes in the four samples: 1788 in common. Being the 60% for the first two samples, and the 90% for the two last samples.

```{r common,cache=FALSE}

type = c("polyA","add-U","add-UU","add-U>3","top 10%","top 5%")
type_name = c("polyA","a","aa","a3","top10","top5")
names(type) = type_name
 void = lapply(type_name, function(x){
     venn(list(s1=genes_s1[[x]],
               s2=genes_s2[[x]],
               s3=genes_s3[[x]],
               s4=genes_s4[[x]]))
     title(type[x])
 })

```


#### s1/s2 with public data

I added here public data using the supplementary table (as PUBLIC in figures)

```{r common-public,cache=FALSE}
 void = lapply(type_name, function(x){
     venn(list(s1=genes_s1[[x]],
               s2=genes_s2[[x]],
               public=genes_public[[x]]))
     title(type[x])
 })
```

### polyA > 30 and size >= 6 nt

```{r poya-filter-30,cache=FALSE}
s1 = filter_out(s1_raw,30)
s2 = filter_out(s2_raw,30)
s3 = filter_out(s3_raw,30)
s4 = filter_out(s4_raw,30)
genes_s1 = get_set_genes(s1)
genes_s2 = get_set_genes(s2)
genes_s3 = get_set_genes(s3)
genes_s4 = get_set_genes(s4)
#rw = filter_out(rw_raw,30)#genes_rw = get_set_genes(rw)
public = filter_out_public(public_raw,30)
genes_public = get_set_genes_public(public)

```

### top family types

Only using the top 1000 expressed genes. There is 25% of ribosomal and histone
genes. 

```{r top40}
plot_family(s1)
plot_family(s2)
plot_family(s3)
plot_family(s4)
```

#### Common genes among 4 samples

```{r common-30,cache=FALSE}

 void = lapply(type_name, function(x){
     venn(list(s1=genes_s1[[x]],
               s2=genes_s2[[x]],
               s3=genes_s3[[x]],
               s4=genes_s4[[x]]))
     title(type[x])
 })

```

#### s1/s2 with public data

```{r common-public-30,cache=FALSE}
 void = lapply(type_name, function(x){
     venn(list(s1=genes_s1[[x]],
               s2=genes_s2[[x]],
               public=genes_public[[x]]))
     title(type[x])
 })
```


## Summary of samples with polyA>30

```{r polya-summary,cache=FALSE}
summary_all(list("s1"=s1,"s2"=s2,"s3"=s3,"s4"=s4))
frequency_u(list("s1"=s1,"s2"=s2,"s3"=s3,"s4"=s4))
```


## Correlation


### Total gene expression

```{r cor,cache=FALSE}
ma = get_counts(list("s1"=s1,"s2"=s2,"s3"=s3,"s4"=s4))
m = log2(ma[[1]][,2:5]+1)
ggpairs(m, alpha=0.4,
        diag = list(continuous = "density"))
ggheatmap.show(ggheatmap(cor(m)))

```

### Genes expression of polyA-transcripts

```{r cor-polyA,cache=FALSE}
m = log2(ma[[2]][,2:5]+1)
ggpairs(m, alpha=0.4,
        diag = list(continuous = "density"))
ggheatmap.show(ggheatmap(cor(m)))

```



###Genes expression of polyA + U modification

```{r cor-a,cache=FALSE}
m = log2(ma[[3]][,2:5]+1)
ggpairs(m, alpha=0.4,
        diag = list(continuous = "density"))
ggheatmap.show(ggheatmap(cor(m)))

```


### Genes expression of polyA + UU modification

```{r cor-aa,cache=FALSE}
m = log2(ma[[4]][,2:5]+1)
ggpairs(m, alpha=0.4,
        diag = list(continuous = "density"))
ggheatmap.show(ggheatmap(cor(m)))
```


### Genes expression of polyA + U>3 modification

```{r cor-c,cache=FALSE}
m = log2(ma[[5]][,2:5]+1)
ggpairs(m, alpha=0.4,
        diag = list(continuous = "density"))
ggheatmap.show(ggheatmap(cor(m)))
```

## By sample analysis

It included stats for each sample and GO enrichment analysis

### Sample 1

```{r do_go-s1, results='asis',cache=FALSE}
files = make_table(s1,  paste0(path_files, "s1") )
files = get_report_links(files)
#read_summary(s1)
#g_ezid = lapply(genes_s1, get_entrez)
#res_go = run_go_enrichment(g_ezid, "s1")
```
```{r table-s1, results='asis',eval=FALSE}
lapply(1:7, function(x){
    knitr::kable(res_go[[x]], caption=type[x])
})
```

[raw table](`r files[1]`) and [formatted table](`r files[2]`)

### Sample 2

```{r do_go-s2, results='asis',cache=FALSE}
#read_summary(s2)
files = make_table(s2,  paste0(path_files, "s2") )
files = get_report_links(files)
#g_ezid = lapply(genes_s2, get_entrez)
#res_go = run_go_enrichment(g_ezid, "s2")
```
```{r table-s2, results='asis',eval=FALSE}
lapply(1:7, function(x){
    knitr::kable(res_go[[x]], caption=type[x])
})
```

[raw table](`r files[1]`) and [formatted table](`r files[2]`)


### Sample 3

```{r do_go-s3, results='asis',cache=FALSE}
#read_summary(s3)
files = make_table(s3,  paste0(path_files, "s3") )
files = get_report_links(files)
#g_ezid = lapply(genes_s3, get_entrez)
#res_go = run_go_enrichment(g_ezid, "s3")
```
```{r table-s3, results='asis',eval=FALSE}
lapply(1:7, function(x){
    knitr::kable(res_go[[x]], caption=type[x])
})
```

[raw table](`r files[1]`) and [formatted table](`r files[2]`)


### Sample 4

```{r do_go-s4, results='asis',cache=FALSE}
#read_summary(s4)
files = make_table(s4, paste0(path_files, "s4") )
files = get_report_links(files)
#g_ezid = lapply(genes_s4, get_entrez)
#res_go = run_go_enrichment(g_ezid, "s4")
```
```{r table-s4, results='asis',eval=FALSE}
lapply(1:7, function(x){
    knitr::kable(res_go[[x]], caption=type[x])
})
```

[raw table](`r files[1]`) and [formatted table](`r files[2]`)


## half-life


### Correlation of half_life with Public data. Chang et al. 2014

Using SP table 1  from Tani et al. 2012 to correlate half_life mRNA with
Uridylation percentage (% reads with U>1 / % reads with polyA). 
```{r hl-sp,cache=FALSE}
#head(sp.f)
hl = read.table("~/ody/projects/daley_mRNA_mod/tani.csv",header=T,sep="\t")
mart = useMart("ensembl", dataset="hsapiens_gene_ensembl")
g <- getBM( attributes=c("ensembl_gene_id","refseq_mrna") , filters=
"refseq_mrna"    , values =as.character(hl$RepName) ,mart=mart)
idx<-match(hl$RepName,g$refseq_mrna)
hl$ens<-g[idx,1]
half_life = hl[!is.na(hl$ens),c("ens","t1.2..h.")]
value = half_life[,2]
value = as.character(value)
value_num = as.numeric(value)
value_num[which(value==">24")] = NA
value_num[which(value=="N.D.")] = NA
half_life$pi=value_num
half_life = half_life[!is.na(value_num),]


sp_hl = merge(sp.f[,c(1,3,13)],half_life)
names(sp_hl)[2:3]=c("polya","ufreq")
ggplot(sp_hl %>% filter(polya>200), aes(y=ufreq,x=pi)) +
    geom_point()+
    geom_smooth(method = "lm")+
    theme_bw()+
    labs(list(title="Public data"))
```


### Corralation with tailseq 2.0
I count only when reads of Uridaylation >= 20.

```{r hl, fig.width=9, fig.height=6,cache=FALSE}

dd_list = list("s1"=s1,"s2"=s2,"s3"=s3,"s4"=s4)
all = lapply(names(dd_list) , function (name){
        #x = normalization(dd_list[[name]])
        x=dd_list[[name]]    
        get_size_gene(x,limit=20) %>% mutate(sample=name)
        })
tab = do.call(rbind,all)
tab_hl = merge(tab, half_life, by=1)
#head(tab_hl)
ggplot(tab_hl %>% filter(sample=="s1"), aes(y=ufreq,x=pi)) +
    geom_point()+
    geom_smooth(method = "lm")+
    labs(list(title="s1"))

ggplot(tab_hl %>% filter(sample=="s2"), aes(y=ufreq,x=pi)) +
    geom_point()+
    geom_smooth(method = "lm")+
    labs(list(title="s2"))

ggplot(tab_hl %>% filter(sample=="s3"), aes(y=ufreq,x=pi)) +
    geom_point()+
    geom_smooth(method = "lm")+
    labs(list(title="s3"))

ggplot(tab_hl %>% filter(sample=="s4"), aes(y=ufreq,x=pi)) +
    geom_point()+
    geom_smooth(method = "lm")+
    labs(list(title="s4"))

```


### Correlation considering polyA size

I did as well taking into account polyA size.

```{r hl_by_size, fig.width=9, fig.height=6,cache=FALSE}

dd_list = list("s1"=s1,"s2"=s2,"s3"=s3,"s4"=s4)
all = lapply(names(dd_list) , function (name){
        #x = normalization(dd_list[[name]])
        x=dd_list[[name]]
        rbind(get_size_gene(x,"<15",10) %>% mutate(sample=name),
        get_size_gene(x,"<25",10) %>% mutate(sample=name),
        get_size_gene(x,">25",10) %>% mutate(sample=name) )
        
        })
tab = do.call(rbind,all)
tab_hl = merge(tab, half_life, by=1)
#head(tab_hl)
ggplot(tab_hl %>% filter(sample=="s1"), aes(y=ufreq,x=pi)) +
    geom_point()+
    geom_smooth(method = "lm")+
    facet_wrap(~size)+
    labs(list(title="s1"))

ggplot(tab_hl %>% filter(sample=="s2"), aes(y=ufreq,x=pi)) +
    geom_point()+
    geom_smooth(method = "lm")+
    facet_wrap(~size)+
    labs(list(title="s2"))

ggplot(tab_hl %>% filter(sample=="s3"), aes(y=ufreq,x=pi)) +
    geom_point()+
    geom_smooth(method = "lm")+
    facet_wrap(~size)+
    labs(list(title="s3"))

ggplot(tab_hl %>% filter(sample=="s4"), aes(y=ufreq,x=pi)) +
    geom_point()+
    geom_smooth(method = "lm")+
    facet_wrap(~size)+
    labs(list(title="s4"))

```

## Duplicated reads

There is a kind of correlation between 
distinct number of reads and total/average/maximum/average_trimmed reads. 

```{r pcr-artifact}
s1_pcr = read.table(paste0(root_path,"/work_rmdup_read2/s1_final_stats.pcr"))
s1_pcr_dd = s1_pcr %>% group_by(V1) %>% summarise(distinct=n(),reads=sum(V3),ave=mean(V3),ave_trim=mean(V3,trim=0.2),max=max(V3),med=median(V3)) %>% ungroup()
s1_pcr_dd = get_biotype(s1_pcr_dd)

ggplot(s1_pcr_dd,aes(x=distinct,y=reads,color="total")) +
    geom_point(alpha=0.3) +
    geom_point(aes(x=distinct,y=ave,color="average"),alpha=0.3) +
    geom_point(aes(x=distinct,y=ave_trim,color="average_trim"),alpha=0.3) +
    geom_point(aes(x=distinct,y=max,color="maximum"),alpha=0.3) +
    scale_y_log10() +scale_x_log10() +
    scale_color_brewer(palette = "Set1")+
    ggtitle("s1: duplicated reads")
```

Maybe that's only due to non-protein coding genes, because they are normally smaller,
and the reads start at the 5' end, so the position is the same.


```{r pcr_artifact-biotype}
s1_pcr_dd$biotype_red = s1_pcr_dd$biotype
s1_pcr_dd$biotype_red[!grepl("protein", s1_pcr_dd$biotype)] = "Other"
ggplot(s1_pcr_dd,aes(x=distinct,y=max,color=biotype_red)) +
    geom_point(alpha=0.3) +
    scale_y_log10() +scale_x_log10() +
    scale_color_brewer(palette = "Set1")+
    ggtitle("s1: duplicated reads")+
    facet_wrap(~biotype_red)
```


If we plot according to size, we see how those duplicated reads are comming from
smaller transcripts. 

```{r pcr_artifact-size}
ref_fn = paste0(root_path,"/work_rmdup_read2/db/ref.bed")
ref=read.table(ref_fn,sep="\t") %>% filter(grepl("transcript",V8)) %>% mutate(size=V3-V2+1)
s1_pcr_dd$size = ref[match(s1_pcr_dd$V1, ref[,4]),"size"]

ggplot(s1_pcr_dd,aes(x=distinct,y=reads,color=cut(size,breaks=c(-1,500,1000,10000000)))) +
    geom_point(alpha=0.7) +
    scale_color_brewer("size",palette="Set1")+
    scale_y_log10() +scale_x_log10() +
    ggtitle("s1: duplicated reads")+
    facet_wrap(~biotype_red)
```

